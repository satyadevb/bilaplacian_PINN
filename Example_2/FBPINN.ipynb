{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from math import exp, sqrt,pi\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "eps = 0.1\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batchflag = True\n",
    "batchsize = 128\n",
    "\n",
    "start = 0.\n",
    "end = 1.\n",
    "x = np.linspace(start,end,100 )\n",
    "y = np.linspace(start,end,100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "x = np.reshape(x, (np.size(x[:]),1))\n",
    "y = np.reshape(y, (np.size(y[:]),1))\n",
    "\n",
    "def actual_soln(eps):\n",
    "    sinpix = np.array([[math.sin(math.pi*ind[0])] for ind in x])\n",
    "    sinpiy = np.array([[math.sin(math.pi*ind[0])] for ind in y])\n",
    "    return ((sinpix)**2) * ((sinpiy)**2)\n",
    "#f = 8*(eps**2)*((math.pi)**4)*(cos2pix*cos2piy - cos2pix*sinpiy*sinpiy - cos2piy*sinpix*sinpix) - 2*((math.pi)**2)*(cos2pix*sinpiy*sinpiy + cos2piy*sinpix*sinpix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(soln,soln_name):\n",
    "    x = np.linspace(start,end,100);y = np.linspace(start,end,100)\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(x,y,soln.reshape(100,100))\n",
    "    plt.title(soln_name)\n",
    "    plt.show()\n",
    "\n",
    "class Swish(nn.Module):\n",
    "\tdef __init__(self, inplace=True):\n",
    "\t\tsuper(Swish, self).__init__()\n",
    "\t\tself.inplace = inplace\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tif self.inplace:\n",
    "\t\t\tx.mul_(torch.sigmoid(x))\n",
    "\t\t\treturn x\n",
    "\t\telse:\n",
    "\t\t\treturn x * torch.sigmoid(x)\n",
    "\t\n",
    "\n",
    "class FBPINN(nn.Module):\n",
    "\thid_dim = 128\n",
    "\tinput_dim = 2 \n",
    "\tdef __init__(self):\n",
    "\t\tsuper(FBPINN, self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.lin0 = nn.Linear(self.input_dim,self.hid_dim)\n",
    "\t\tself.lin = nn.Linear(self.hid_dim,self.hid_dim)\n",
    "\t\tself.lin1 = nn.Linear(self.hid_dim,1)\n",
    "\t\tself.swish = Swish()\n",
    "\n",
    "\n",
    "\tdef forward(self,x):\t\t\n",
    "\t\ttanh1 = self.tanh(x)\n",
    "\t\ttanh2 = self.tanh(1 - x)\n",
    "\t\ttanh11 = (tanh1[:,0].unsqueeze(1))*(tanh1[:,1].unsqueeze(1))*(tanh1[:,0].unsqueeze(1))*(tanh1[:,1].unsqueeze(1))\n",
    "\t\ttanh22 = (tanh2[:,0].unsqueeze(1))*(tanh2[:,1].unsqueeze(1))*(tanh2[:,0].unsqueeze(1))*(tanh2[:,1].unsqueeze(1))\n",
    "\t\tx = self.lin0(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin1(x)\n",
    "\t\tout = x*tanh11*tanh22\n",
    "\t\treturn  out\n",
    "\n",
    "def lag_coeffs(num):\n",
    "\t\tlis = [np.array([1]),np.array([1,-1])]\n",
    "\t\tfor n in range(1,num-1):\n",
    "\t\t\txl1 = np.concatenate((np.array([0]),lis[n]),axis = 0)\n",
    "\t\t\tl1 = np.concatenate((lis[n],np.array([0])),axis = 0)\t\t\n",
    "\t\t\tl0 = np.concatenate((lis[n-1],np.array([0,0])),axis = 0)\n",
    "\t\t\tl = ((2*n + 1)*l1 - xl1 - n*l0)/(n + 1)\n",
    "\t\t\tlis.append(l)\n",
    "\t\tfor n in range(num):\n",
    "\t\t\tlis[n] = np.concatenate((lis[n],np.array([0]*(num-1-n))),axis = 0)\n",
    "\t\treturn lis\n",
    "\n",
    "def poly(coeffs,x):\n",
    "\tsum = torch.zeros_like(x)\n",
    "\tfor i,coeff in enumerate(coeffs):\n",
    "\t\tsum = sum + coeff*(x**i)\n",
    "\treturn sum\n",
    "\n",
    "class Lag_FBPINN(nn.Module):\n",
    "\tdef __init__(self,basis_num):\n",
    "\t\tsuper(Lag_FBPINN,self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.basis_num = basis_num\n",
    "\t\tself.main = nn.Sequential(\n",
    "\t\t\t#nn.Linear(2*basis_num,2*basis_num),\n",
    "\t\t\tnn.Linear(2*basis_num,1))\t\t\n",
    "\tdef forward(self,input):\n",
    "\t\ttanh1 = self.tanh(input)\n",
    "\t\ttanh2 = self.tanh(1 - input)\n",
    "\t\ttanh11 = (tanh1[:,0].unsqueeze(1))*(tanh1[:,1].unsqueeze(1))*(tanh1[:,0].unsqueeze(1))*(tanh1[:,1].unsqueeze(1))\n",
    "\t\ttanh22 = (tanh2[:,0].unsqueeze(1))*(tanh2[:,1].unsqueeze(1))*(tanh2[:,0].unsqueeze(1))*(tanh2[:,1].unsqueeze(1))\n",
    "\t\tcoeffs = lag_coeffs(self.basis_num)\n",
    "\t\tx = input[:,0]\n",
    "\t\tt = input[:,1]\n",
    "\t\tnetin = torch.Tensor([])\n",
    "\t\tfor i in range(self.basis_num):\n",
    "\t\t\tnetin = torch.cat((netin,poly(coeffs[i],x.view(-1,1))),1)\n",
    "\t\tfor i in range(self.basis_num):\n",
    "\t\t\tnetin = torch.cat((netin,poly(coeffs[i],t.view(-1,1))),1)\n",
    "\t\tnetout = self.main(netin)\n",
    "\t\treturn netout*tanh11*tanh22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(device,x,y,eps,learning_rate,epochs,batch_flag,batch_size):\n",
    "\n",
    "\txnet = torch.Tensor(x)\n",
    "\tynet = torch.Tensor(y) \n",
    "\tif(batch_flag):\n",
    "\t\tdataset = TensorDataset(xnet,ynet)\n",
    "\t\tdataloader = DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers = 0,drop_last = True )\n",
    "\t\tprint(len(dataloader))\n",
    "\n",
    "\tnet = FBPINN()#.to(device)\n",
    "\t\n",
    "\tdef init_normal(m):\n",
    "\t\tif type(m) == nn.Linear:\n",
    "\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\tnet.apply(init_normal)\n",
    "\n",
    "\toptimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\tdef Loss_criterion(xnet,ynet):\n",
    "\t\txnet.requires_grad = True\n",
    "\t\tynet.requires_grad = True\n",
    "\t\tpoints = torch.cat((xnet,ynet),1) \n",
    "\t\tU = net(points)\n",
    "\t\tU = U.view(len(U),-1)\n",
    "\t\t\n",
    "\t\tsoln = (torch.sin(np.pi*xnet))**2 * (torch.sin(np.pi*ynet))**2\n",
    "\t\t\n",
    "\t\tsoln_x = torch.autograd.grad(soln,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xx = torch.autograd.grad(soln_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxx = torch.autograd.grad(soln_xx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxxx = torch.autograd.grad(soln_xxx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_y = torch.autograd.grad(soln,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yy = torch.autograd.grad(soln_y,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yyy = torch.autograd.grad(soln_yy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yyyy = torch.autograd.grad(soln_yyy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxy = torch.autograd.grad(soln_xx,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxyy = torch.autograd.grad(soln_xxy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\t\n",
    "\t\tf = (eps**2)*(soln_xxxx + soln_yyyy + 2*soln_xxyy) - (soln_xx + soln_yy)\n",
    "\t\t\n",
    "\t\tU_x = torch.autograd.grad(U,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xx = torch.autograd.grad(U_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxx = torch.autograd.grad(U_xx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxxx = torch.autograd.grad(U_xxx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_y = torch.autograd.grad(U,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yy = torch.autograd.grad(U_y,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yyy = torch.autograd.grad(U_yy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yyyy = torch.autograd.grad(U_yyy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxy = torch.autograd.grad(U_xx,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxyy = torch.autograd.grad(U_xxy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tloss1 = (eps**2)*(U_xxxx + U_yyyy + 2*U_xxyy) - (U_xx + U_yy) - f \n",
    "\t\t\n",
    "\t\treturn nn.MSELoss()(loss1,torch.zeros_like(loss1)) \n",
    "\n",
    "\tlosses = [];errors = []\n",
    "\ttic = time.time()\n",
    "\n",
    "\tif(batch_flag):\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 30:\n",
    "\t\t\t\tlearning_rate = 0.00001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\tfor batch_idx, (x_in,y_in) in enumerate(dataloader):\n",
    "\n",
    "\t\t\t\tnet.zero_grad()\n",
    "\t\t\t\tloss = Loss_criterion(x_in,y_in)\n",
    "\t\t\t\tloss.backward()\n",
    "\n",
    "\t\t\t\toptimizer.step() \n",
    "\t\t\t\tif batch_idx % 20 ==0:\n",
    "\t\t\t\t\tprint('Train Epoch: {} \\tLoss: {:.20f}'.format(epoch, loss.item()))\n",
    "\n",
    "\t\t\tpoints = torch.cat((xnet,ynet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tactual_loss = np.square(actual_soln(eps) - z).mean()\n",
    "\t\t\tprint('\\nAfter Epoch {}, \\t Actual solution loss: {:.20f}\\n'.format(\n",
    "\t\t\t\tepoch, actual_loss))\n",
    "\t\t\tif epoch % 1 == 0:\n",
    "\t\t\t\tplot_graph(z,'Predicted solution')\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\t\t\terrors.append(actual_loss)\n",
    "\n",
    "\telse:\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 50:\n",
    "\t\t\t\tlearning_rate = 0.00001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\n",
    "\t\t\tnet.zero_grad()\n",
    "\t\t\tloss = Loss_criterion(xnet,ynet)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t\n",
    "\t\t\toptimizer.step() \n",
    "\t\t\tpoints = torch.cat((xnet,ynet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tactual_loss = np.square(actual_soln - z).mean()\n",
    "\t\t\tprint('\\nAfter Epoch {}, \\t Actual solution loss: {:.10f}\\n'.format(\n",
    "\t\t\t\tepoch, actual_loss))\n",
    "\t\t\tif epoch % 5 == 0:\n",
    "\t\t\t\tplot_graph(z,'Predicted solution')\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\t\t\terrors.append(actual_loss)\n",
    "\n",
    "\ttoc = time.time()\n",
    "\telapseTime = toc - tic\n",
    "\tprint (\"Time elapsed = \", elapseTime)\n",
    "\n",
    "\tnet_in = torch.cat((xnet,ynet),1)\n",
    "\toutput = net(net_in)  \n",
    "\t\n",
    "\treturn output,losses,errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(actual_soln(eps),'Actual solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,losses,errors = train(device,x,y,eps,learning_rate,epochs,batchflag,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = output.detach().numpy()\n",
    "plot_graph(z,\"Predicted Solution\")\n",
    "plot_graph(actual_soln(eps),\"Actual Solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
