{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from math import exp, sqrt,pi\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = 0.\n",
    "end = 1.\n",
    "\n",
    "x = np.linspace(start,end,100 )\n",
    "y = np.linspace(start,end,100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "x = np.reshape(x, (np.size(x[:]),1))\n",
    "y = np.reshape(y, (np.size(y[:]),1))\n",
    "\n",
    "xb1 = np.linspace(start,start, 100 )\n",
    "yb1 = np.linspace(start,end, 100 ) \n",
    "xb1 = xb1.reshape(-1, 1)\n",
    "yb1 = yb1.reshape(-1, 1)\n",
    "\n",
    "xb2 = np.linspace(start,end, 100 )\n",
    "yb2 = np.linspace(end,end, 100 ) \n",
    "xb2 = xb2.reshape(-1, 1)\n",
    "yb2 = yb2.reshape(-1, 1)\n",
    "\n",
    "xb3 = np.linspace(end,end, 100 )\n",
    "yb3 = np.linspace(start,end, 100 ) \n",
    "xb3 = xb3.reshape(-1, 1)\n",
    "yb3 = yb3.reshape(-1, 1)\n",
    "\n",
    "xb4 = np.linspace(start,end, 100 )\n",
    "yb4 = np.linspace(start,start, 100 ) \n",
    "xb4 = xb4.reshape(-1, 1)\n",
    "yb4 = yb4.reshape(-1, 1)\n",
    "\n",
    "xb = [xb1,xb2,xb3,xb4]\n",
    "yb = [yb1,yb2,yb3,yb4]\n",
    "\n",
    "def actual_soln(eps):\n",
    "    sinpix = np.array([[math.sin(math.pi*ind[0])] for ind in x])\n",
    "    sinpiy = np.array([[math.sin(math.pi*ind[0])] for ind in y])\n",
    "    return ((sinpix)**2) * ((sinpiy)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(soln,soln_name):\n",
    "    x = np.linspace(start,end,100);y = np.linspace(start,end,100)\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(x,y,soln.reshape(100,100))\n",
    "    plt.title(soln_name)\n",
    "    plt.show()\n",
    "\n",
    "class Swish(nn.Module):\n",
    "\tdef __init__(self, inplace=True):\n",
    "\t\tsuper(Swish, self).__init__()\n",
    "\t\tself.inplace = inplace\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tif self.inplace:\n",
    "\t\t\tx.mul_(torch.sigmoid(x))\n",
    "\t\t\treturn x\n",
    "\t\telse:\n",
    "\t\t\treturn x * torch.sigmoid(x)\n",
    "\t\n",
    "\n",
    "class PINN(nn.Module):\n",
    "\thid_dim = 128\n",
    "\tinput_dim = 2 \n",
    "\tdef __init__(self):\n",
    "\t\tsuper(PINN, self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.lin0 = nn.Linear(self.input_dim,self.hid_dim)\n",
    "\t\tself.lin = nn.Linear(self.hid_dim,self.hid_dim)\n",
    "\t\tself.lin1 = nn.Linear(self.hid_dim,1)\n",
    "\t\tself.swish = Swish()\n",
    "\n",
    "\n",
    "\tdef forward(self,x):\t\t\n",
    "\t\tx = self.lin0(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin1(x)\n",
    "\t\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device,x,y,xb,yb,eps,learning_rate,epochs,batch_flag,batch_size):\n",
    "\txnet = torch.Tensor(x).to(device)\n",
    "\tynet = torch.Tensor(y).to(device) \n",
    "\txb1,xb2,xb3,xb4 = xb\n",
    "\tyb1,yb2,yb3,yb4 = yb\n",
    "\txb1 = torch.Tensor(xb1).to(device) \t\n",
    "\tyb1 = torch.Tensor(yb1).to(device) \n",
    "\txb2 = torch.Tensor(xb2).to(device) \t\n",
    "\tyb2 = torch.Tensor(yb2).to(device) \n",
    "\txb3 = torch.Tensor(xb3).to(device) \t\n",
    "\tyb3 = torch.Tensor(yb3).to(device) \n",
    "\txb4 = torch.Tensor(xb4).to(device) \t\n",
    "\tyb4 = torch.Tensor(yb4).to(device) \n",
    "\n",
    "\tif(batch_flag):\n",
    "\t\tdataset = TensorDataset(xnet,ynet)\n",
    "\t\tdataloader = DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers = 0,drop_last = True )\n",
    "\t\n",
    "\tnet = PINN().to(device)\n",
    "\t\n",
    "\tdef init_normal(m):\n",
    "\t\tif type(m) == nn.Linear:\n",
    "\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\tnet.apply(init_normal)\n",
    "\n",
    "\toptimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\tdef Loss_criterion(xnet,ynet):\n",
    "\t\txnet.requires_grad = True\n",
    "\t\tynet.requires_grad = True\n",
    "\t\tpoints = torch.cat((xnet,ynet),1) \n",
    "\t\tU = net(points)\n",
    "\n",
    "\t\tU = U.view(len(U),-1)\n",
    "\n",
    "\t\tsoln = (torch.sin(np.pi*xnet))**2 * (torch.sin(np.pi*ynet))**2\n",
    "\t\tsoln_x = torch.autograd.grad(soln,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xx = torch.autograd.grad(soln_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxx = torch.autograd.grad(soln_xx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxxx = torch.autograd.grad(soln_xxx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_y = torch.autograd.grad(soln,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yy = torch.autograd.grad(soln_y,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yyy = torch.autograd.grad(soln_yy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yyyy = torch.autograd.grad(soln_yyy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxy = torch.autograd.grad(soln_xx,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxyy = torch.autograd.grad(soln_xxy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tf = (eps**2)*(soln_xxxx + soln_yyyy + 2*soln_xxyy) - (soln_xx + soln_yy)\n",
    "\n",
    "\t\tU_x = torch.autograd.grad(U,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xx = torch.autograd.grad(U_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxx = torch.autograd.grad(U_xx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxxx = torch.autograd.grad(U_xxx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_y = torch.autograd.grad(U,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yy = torch.autograd.grad(U_y,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yyy = torch.autograd.grad(U_yy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yyyy = torch.autograd.grad(U_yyy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxy = torch.autograd.grad(U_xx,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxyy = torch.autograd.grad(U_xxy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tloss1 = (eps**2)*(U_xxxx + U_yyyy + 2*U_xxyy) - (U_xx + U_yy) - f \n",
    "\t\treturn nn.MSELoss()(loss1,torch.zeros_like(loss1)) \n",
    "\n",
    "\tdef Loss_BC(xb1,xb2,xb3,xb4,yb1,yb2,yb3,yb4):\n",
    "\t\t\n",
    "\t\txb1.requires_grad = True\n",
    "\t\tyb1.requires_grad = True\n",
    "\t\txb2.requires_grad = True\n",
    "\t\tyb2.requires_grad = True\n",
    "\t\txb3.requires_grad = True\n",
    "\t\tyb3.requires_grad = True\n",
    "\t\txb4.requires_grad = True\n",
    "\t\tyb4.requires_grad = True\n",
    "\t\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\n",
    "\n",
    "\t\tnet1 = torch.cat((xb1, yb1), 1)\n",
    "\t\tout1 = net(net1)\n",
    "\t\tub1 = out1.view(len(out1), -1)\n",
    "\t\tder_ub1 = torch.autograd.grad(ub1,xb1,grad_outputs=torch.ones_like(xb1),create_graph = True,only_inputs=True)[0]\n",
    "\n",
    "\t\tloss_dirichlet1 = loss_f(ub1,torch.zeros_like(ub1))\n",
    "\t\tloss_neumann1 = loss_f(der_ub1,torch.zeros_like(der_ub1))\n",
    "\n",
    "\t\tnet2 = torch.cat((xb2, yb2), 1)\n",
    "\t\tout2 = net(net2)\n",
    "\t\tub2 = out2.view(len(out2), -1)\n",
    "\t\tder_ub2 = torch.autograd.grad(ub2,yb2,grad_outputs=torch.ones_like(yb2),create_graph = True,only_inputs=True)[0]\n",
    "\n",
    "\t\tloss_dirichlet2 = loss_f(ub2,torch.zeros_like(ub2))\n",
    "\t\tloss_neumann2 = loss_f(der_ub2,torch.zeros_like(der_ub2))\n",
    "\n",
    "\t\tnet3 = torch.cat((xb3, yb3), 1)\n",
    "\t\tout3 = net(net3)\n",
    "\t\tub3 = out3.view(len(out3), -1)\n",
    "\t\tder_ub3 = torch.autograd.grad(ub3,xb3,grad_outputs=torch.ones_like(xb3),create_graph = True,only_inputs=True)[0]\n",
    "\n",
    "\t\tloss_dirichlet3 = loss_f(ub3,torch.zeros_like(ub3))\n",
    "\t\tloss_neumann3 = loss_f(der_ub3,torch.zeros_like(der_ub3))\n",
    "\n",
    "\t\tnet4 = torch.cat((xb4, yb4), 1)\n",
    "\t\tout4 = net(net4)\n",
    "\t\tub4 = out4.view(len(out4), -1)\n",
    "\t\tder_ub4 = torch.autograd.grad(ub4,yb4,grad_outputs=torch.ones_like(yb4),create_graph = True,only_inputs=True)[0]\n",
    "\n",
    "\t\tloss_dirichlet4 = loss_f(ub4,torch.zeros_like(ub4))\n",
    "\t\tloss_neumann4 = loss_f(der_ub4,torch.zeros_like(der_ub4))\n",
    "\n",
    "\t\ttotal_loss = loss_dirichlet1 + loss_neumann1 + loss_dirichlet2 + loss_neumann2 + loss_dirichlet3 + loss_neumann3 + loss_dirichlet4 + loss_neumann4 \n",
    "\t\treturn total_loss\n",
    "\n",
    "\tlosses = [];errors = []\n",
    "\ttic = time.time()\n",
    "\n",
    "\n",
    "\tif(batch_flag):\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 40:\n",
    "\t\t\t\tlearning_rate = 0.0001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\tfor batch_idx, (x_in,y_in) in enumerate(dataloader):\n",
    "\n",
    "\t\t\t\tnet.zero_grad()\n",
    "\t\t\t\tloss_eqn = Loss_criterion(x_in,y_in)\n",
    "\t\t\t\tloss_bc = Loss_BC(xb1,xb2,xb3,xb4,yb1,yb2,yb3,yb4)\n",
    "\t\t\t\tloss = loss_eqn + loss_bc\n",
    "\t\t\t\tloss.backward()\n",
    "\n",
    "\t\t\t\toptimizer.step() \n",
    "\t\t\t\tif batch_idx % 20 ==0:\n",
    "\t\t\t\t\tprint('Train Epoch: {} \\nTotal Loss: {:.10f} \\tCriterion Loss: {:.10f} \\tBoundary Condition Loss {:.6f}'.format(\n",
    "\t\t\t\t\tepoch, loss.item(),loss_eqn.item(),loss_bc.item()))\n",
    "\n",
    "\t\t\tpoints = torch.cat((xnet,ynet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tactual_loss = np.square(actual_soln(eps) - z).mean()\n",
    "\t\t\tprint('\\nAfter Epoch {}, \\t Actual solution loss: {:.10f}\\n'.format(\n",
    "\t\t\t\tepoch, actual_loss))\n",
    "\t\t\tif epoch % 1 == 0:\n",
    "\t\t\t\tplot_graph(z,'Predicted solution')\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\t\t\terrors.append(actual_loss)\n",
    "\telse:\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 100:\n",
    "\t\t\t\tlearning_rate = 0.0001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\n",
    "\t\t\tnet.zero_grad()\n",
    "\t\t\tloss_eqn = Loss_criterion(xnet,ynet)\n",
    "\t\t\tloss_bc = Loss_BC(xb1,xb2,xb3,xb4,yb1,yb2,yb3,yb4)\n",
    "\t\t\tloss = loss_eqn + loss_bc\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t\n",
    "\t\t\toptimizer.step() \n",
    "\t\t\tpoints = torch.cat((xnet,ynet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tactual_loss = np.square(actual_soln(eps) - z).mean()\n",
    "\t\t\tif epoch % 5 == 0:\n",
    "\t\t\t\tplot_graph(z,\"soln\")\n",
    "\t\t\tprint('Train Epoch: {} \\nTotal Loss: {:.10f} \\tCriterion Loss: {:.10f} \\tBoundary Condition Loss {:.6f}\\nActual loss: {:.6f}'.format(\n",
    "\t\t\t\tepoch, loss.item(),loss_eqn.item(),loss_bc.item(),actual_loss))\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\t\t\terrors.append(actual_loss)\n",
    "\n",
    "\ttoc = time.time()\n",
    "\telapseTime = toc - tic\n",
    "\tprint (\"elapse time in parallel = \", elapseTime)\n",
    "\n",
    "\tnet_in = torch.cat((xnet,ynet),1)\n",
    "\toutput = net(net_in)  \n",
    "\t\n",
    "\treturn output,losses,errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1\n",
    "plot_graph(actual_soln(eps),'Actual solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "batchsize = 128 \n",
    "learning_rate = 1e-3\n",
    "batch_flag = True\n",
    "batch_size = 128\n",
    "\n",
    "output,losses,errors = train(device,x,y,xb,yb,eps,learning_rate,epochs,batch_flag,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = output.detach().numpy()\n",
    "plot_graph(z,\"Predicted Solution\")\n",
    "plot_graph(actual_soln(eps),\"Actual Solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
